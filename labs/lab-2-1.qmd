---
title: "Lab 2-1 - Visualizing socioeconomic outcomes by T station"
author: "Hamish Gibbs"
institute:
  - Network Science Institute, Northeastern University
  - NETS 7983 Computational Urban Science
  - Last updated `r Sys.Date()`
format: html
code-line-numbers: false
execute:
  echo: true
#  cache: true
  warning: false
  messages: false
editor: visual
logo: ./img/sunlab.png
footer: "CUS, Northeastern Spring 2025"
link-external-icon: true
link-external-newwindow: true
bibliography: references.bib
---

## Objective

In this practical, we will re-create and extend an analysis of variation in census variables by T stations in Boston: [*Health Inequalities in Boston by T-Stops: A Pictorial Essay*](https://www.bu.edu/sph/news/articles/2015/health-of-a-city-health-inequalities-in-boston-by-t-stops-a-pictorial-essay/). This follows another analysis of life expectancy at tube stations in London. The idea of these types of visualizations is to connect relatively abstract statistics from the census with the more familiar public transit network, making it easier to understand how greatly health or socioeconomic outcomes can vary across a relatively short distances within a city.

In this practical, we will learn to:

-   Retrieve, process, and analyze census data for different geographies / variables.
-   Combine geo-referenced census data with other spatial features (from Open Street Map) for analysis.
-   Refine visualizations to effectively communicate urban dynamics.

## Before starting:

1.  Ensure you have access to the `stella` server:

2.  [Request a U.S. Census Data API Key](https://api.census.gov/data/key_signup.html)

3.  Load required packages

    ```{r}
    library(tidycensus)
    library(tidyverse)
    library(tigris)
    library(sf)
    library(osmdata)
    library(leaflet)
    library(arrow)
    library(corrplot)
    library(factoextra)
    ```

4.  Configure the API key in your R environment

    ``` r
    Sys.setenv(CENSUS_API_KEY = "YOUR_API_KEY")
    ```

5.  Then call the `tidycensus::census_api_key` function:

    ```{r}
    census_api_key(Sys.getenv("CENSUS_API_KEY"), install = TRUE, overwrite=TRUE)
    ```

## Loading Census Data

To recap, the `tidycensus` package gives us a simple way to retrieve census data for a given variable and set of geographic units.

*Note: in this practical, we will use data from the American Community Survey (ACS) because of the greater number of variables. To do this, we will use the `tidyverse::get_acs` function. The decennial census is also available with `tidyverse::get_decennial`.*

Lets start by retrieving median household income in US states. For a list of the different variables available from the ACS, a good place to start is the [ACS Variable Explorer](https://www.census.gov/programs-surveys/acs/guidance/subjects.html). If you know what you are looking for, you can use the search bar to find the variable code(s).

```{r}
medincome <- get_acs(geography = "state", 
                   variables = "B19013_001", 
                   year = 2020)

head(medincome)
```

## Exercise 1

-   Try downloading other variables using codes you find with the [ACS Variable Explorer](https://www.census.gov/programs-surveys/acs/guidance/subjects.html). Are cross-tabulations of multiple variables in the same format as univariate tables?

-   Inspect all of the variables available in the 2021 ACS. `tidycensus` has a helpful function for this: `load_variables(2021, "acs5", cache = TRUE)` .

-   The beginning of the variable code indicates the table. What does the suffix `_001` in the code block above indicate?

## Mapping Census Data

`tidycensus` integrates with `sf` to return spatial boundaries for geographic units. We can add spatial boundaries using `geometry = TRUE`.

```{r}
medincome <- get_acs(geography = "state", 
                     variables = "B19013_001", 
                     year = 2021,
                     geometry=TRUE)

ggplot(medincome) + 
    geom_sf(aes(fill=estimate))
```

We can simplify the plot by restricting to states in the continental US.

```{r}
medincome_continental_usa <- medincome %>% 
    filter(!NAME %in% c("Alaska", "Hawaii", "Guam", "Puerto Rico"))

ggplot(medincome_continental_usa) + 
    geom_sf(aes(fill=estimate))
```

Remember the hierarchy of US statistical geographies? You can download data for any of these geographies with `tidycensus`.

![](https://walker-data.com/umich-workshop-2022/intro-2020-census/img/census_diagram.png)

See the list of available geographies [here](https://walker-data.com/tidycensus/articles/basic-usage.html#geography-in-tidycensus).

We can also filter for some higher-level geographies. Lets get median household income for Census Block Groups in Massachusetts.

```{r}
medincome_ma <- get_acs(
  geography = "cbg",
  variables = "B19013_001",
  survey = "acs5",
  year = 2021,
  state = "MA",
  geometry = TRUE
)

head(medincome_ma)
```

We only want data for Boston, so we will have to filter for CBGs within the boundary of Boston. We can get this boundary from `tigris`, an R package that provides access to Census geographic boundaries and is closely coupled to `tidycensus`. See [Census geographic data and applications in R](https://walker-data.com/census-r/census-geographic-data-and-applications-in-r.html) for more information.

```{r}
boston_area_towns <- c("Boston", "Somerville", "Cambridge", "Brookline", "Revere", "Malden", "Everett", "Medford", "Chelsea", "Winthrop Town")
boston_boundary <- places(state = "MA", cb = TRUE, year=2021) %>%
  filter(NAME %in% boston_area_towns)
```

## Exercise 2

-   Using what you learned in lab-1-1, check that the Boston boundary is correct by plotting it on an interactive map using `leaflet`.

## Restricting Census data to our area of interest

Now, using `st_filter` from the `sf` package, we can filter for CBGs within Boston.

```{r}
medincome_boston <- medincome_ma %>%
  st_filter(boston_boundary)

head(medincome_boston)
```

We can then make a Choropleth map of the income in CBGs.

```{r}
ggplot(medincome_boston) +
  geom_sf(aes(fill = estimate), color = NA)
```

## Exercise 3

-   What is causing the missing values for some of these areas? *Tip: Removing CBGs with `NA` values and plotting with `leaflet` may give some indication.*

## Sidenote: using data visualizations to communicate your findings

Data visualizations are the best tool you have for conveying the results of your analysis. When done right, they are interesting, compelling, and can contain much more information that you could write down concisely. When they are done wrong, that can confuse your audience or distract from the important message you are trying to convey. It is well worth spending a bit of effort to (1) **think through how to best display your data**, (2) **take a extra time to polish your visualization**, (3) **be prepared to make and re-make your visualization as things change**. Making a compelling data visualization if often a question of choosing which dimensions in your data that are most important for the message you are trying to convey, then finding a type of plot that can represent them clearly. There is some inspiration in the [R Graph Gallery](https://r-graph-gallery.com/).

Things to keep in mind:

-   Are your axis labels human readable?

-   Does your plot have an appropriate theme? Grid-lines (in default ggplot theme) are often not relevant or need to be reduced.

-   Have you considered how you are using color? Common mistakes include: colors over-emphasizing minor variations in your data, diverging color scales used for non-diverging data, forgetting accessibility for color blind people.

-   (Sometimes) Do you have a **declarative title** conveying the main message of your visualization?

More generally, consider Edward Tufte's data visualization design principles:

1.  Above all else show data.

2.  Maximize the data-ink ratio.

3.  Erase non-data-ink.

4.  Erase redundant data-ink.

5.  Revise and edit.

Here is a cleaned up version of the map.

```{r}
ggplot() +
  geom_sf(data = medincome_boston, aes(fill = estimate), color = NA, alpha = 0.8) +
  scale_fill_viridis_c(option = "magma", direction = 1, name = "MHI", label = function(x){paste0("$", scales::comma(x))}) + 
  theme_void() +
  labs(
    title = "Median Household Income (2021)",
    subtitle = "Block Groups in Boston"
  ) + 
theme(legend.position = c(0.8, 0.2))
```

## Exercise 4

-   List a few additions that could make this map more compelling.

## Combining census data with OSM

Now, lets start combining our census data with data from open street map.

We will follow this methodology:

1.  Download a range of ACS variables.
2.  Download Public Transit Stops in Boston from Open Street Map.
3.  Compute the "accessibility" of transit stations from CBGs.
4.  Explore which census variables predict transit station accessibility.

## Retrieving ACS Variables

Now, lets retrieve a few more variables from the ACS. Because combining ACS variables can be complicated (for example, we might want broad age categories, not one year bands), we have pre-processed a few key variables into an easier-to-use format. You can find this in the file `/data/CUS/labs/2/14460_acs_2021_filtered.parquet`.

```{r}
census <- read_parquet("/data/CUS/labs/2/14460_acs_2021_filtered_boston.parquet")
colnames(census)
```

## Exercise 5

-   Take a moment to re-construct one of the variables (like `age.u1825`) in this data frame using `tidycensus` and the [ACS Variable Explorer](https://www.census.gov/programs-surveys/acs/guidance/subjects.html).

Because the `census` variable doesn't have any associated geography, we need to download and attach geographies using the `tigris` package.

```{r}
block_groups <- block_groups(state = "25", year = 2021, class = "sf")
census <- census %>% 
    left_join(block_groups %>% select(GEOID, geometry), by = c("GEOID")) %>% 
    st_as_sf()
census
```

## Retrieving OSM data

Now that we have some nicely formatted census data, we can move on to downloading our transit stations from OSM.

We have already loaded ACS data for CBGs in Boston. Now we need to retrieve public transit stations from OSM. We can do this using the `osmdata` R package (as we did in last week's practical).

```{r}
boston_bb <- getbb("Boston, Massachusetts")
public_transit_pts <- opq(bbox = boston_bb) %>%
  add_osm_feature(key = "public_transport", value = "station") %>%
  osmdata_sf()

public_transit_pts <- public_transit_pts$osm_points
head(public_transit_pts)
```

Lets display the data in an interactive map that will let us check that we have downloaded the correct features.

```{r}
leaflet(public_transit_pts) %>%
  addProviderTiles(provider=providers$CartoDB.Positron) %>%
  addCircleMarkers(
    label = ~name,
    radius = 3,
    stroke = FALSE,
    fillOpacity = 0.8,
    color = "blue"
  )
```

It looks like this data has some duplicated stations, and isn't restricted to T-stops. This is a common problem in OSM data, which is crowd-sourced from volunteers.

Let's see if we can filter the data to select only T stops. First, we can check the unique values in the station column.

```{r}
public_transit_pts %>% pull(station) %>% unique()
```

Then, lets filter for "subway" and "light_rail" stations.

```{r}
t_stops <- public_transit_pts %>%
  filter(station %in% c("subway", "light_rail"))

leaflet(t_stops) %>%
  addProviderTiles(provider=providers$CartoDB.Positron) %>%
  addCircleMarkers(
    label = ~name,
    radius = 3,
    stroke = FALSE,
    fillOpacity = 0.8,
    color = "blue"
  )
```

This looks pretty good!

## Exercise 6

-   Take a moment to explore OSM data. What other features are accessible? Can you find features for other forms of public transit? Can you identify any limitations cause by the crowd-sourced nature of the data?

    -   For a list of all of the features available from Open Street Map, see [here](https://wiki.openstreetmap.org/wiki/Map_features).

## Measuring transit accessibility

Now that we have data on census variables in geographic areas and the location of public transit stations, we can move on to calculating a measure of public transit accessibility.

Our measure will be based on the assumption of *proximity-based accessibility* and *residential anchoring*. This means that the proximity of an individual's home to a transit station (in terms of geometric distance) is indicative of higher / lower public transit accessibility.

## Exercise 7

-   Take a moment to consider the assumptions underlying the ideas of *proximity-based accessibility* and *residential anchoring.* Could large-scale behavioral data shed more light on people's true patterns of behavior in the city?

-   Why do you think that these ideas have been widely adopted in traditional urban studies (in transit accessibility studies like this one, as well as concepts such as urban food deserts)?

## Computing a measure of transit accessibility

In order to compute the proximity of Census Block Groups to transit stations, we can use the `st_distance` function to calculate the distance from each Block Group to the nearest transit station.

To make sure our distance calculation is accurate, we need to transform our data into a projected coordinate system (which preserves distance). Because of our study area, we can use the

```{r}
t_stops <- t_stops %>% st_transform(26986)
census <- census %>% st_transform(26986)
```

Now we can compute the distance from each CBG to the nearest transit station.

```{r}
distances <- st_distance(census, t_stops)
census$nearest_t_stop_dist <- apply(distances, 1, min)
census %>% select(GEOID, nearest_t_stop_dist)
```

*Tip: if you don't understand an expression like this, take a moment to break it down one by one. For example, try inspecting the `distances`* variable, or running only the expression `apply(distances, 1, min)`.

## Exercise 8

-   Make a map of the `nearest_t_stop_dist` distance variable, with the `t_stops` variable overlaid on top.

## Predicting transit accessibility

Now that we have prepared our data, we can ask the question: *what census variables predict the accessibility of transit stations?*

We can start with a simple approach: a linear regression of: `accessibility measure ~ block group characteristics`. To do this efficiently, I'm using the `as.formula` function from base R. Again, if you are new to R, take a moment to break down this expression piece-by-piece to understand how each component works.

```{r}
predictors <- setdiff(names(census %>% select(-GEOID) %>% st_drop_geometry()), "nearest_t_stop_dist")
lm_formula <- as.formula(paste("nearest_t_stop_dist ~", paste(predictors, collapse = " + ")))
print(lm_formula)
```

```{r}
census <- census %>% drop_na()
```

Now that we have the formula for our regression, we can create our model and inspect the results.

```{r}
model <- lm(lm_formula, data = census %>% select(-GEOID) %>% st_drop_geometry())
summary(model)
```

## Exercise 9

-   Try to interpret these model results.

    -   Which variables are *positively* associated with `nearest_t_stop_dist`?

    -   Which variables are *negatively* associated?

    -   Why are some estimates `NA`?

    -   What does this indicate about the quantity of information contained in certain census variables?

    -   How many variables have any statistical significance?

    -   What is the overall power of these variables to predict `nearest_t_stop_dist`?

## Multicollinearity of census variables

```{r}
corrplot(cor(census %>% select(-GEOID, -nearest_t_stop_dist) %>% st_drop_geometry()), method="number")
```

## Dimensionality reduction of census variables

```{r}
pca <- prcomp(census %>% select(-GEOID, -nearest_t_stop_dist) %>% st_drop_geometry(), scale. = TRUE)
```

scree plot

```{r}
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50), ncp=Inf)
```

## Exercise

-   What proportion of variance is explained by the top 3 components?

biplot

```{r}
fviz_pca_biplot(pca, repel = TRUE, col.var = "blue", col.ind = NA)
```

Individual contributions

```{r}
fviz_pca_ind(pca, col.ind = "cos2", gradient.cols = c("blue", "green", "red"))
```

```{r}
cor_matrix <- cor(census %>% select(-GEOID, -nearest_t_stop_dist) %>% st_drop_geometry(), pca$x)
corrplot(cor_matrix, method = "color", is.corr = FALSE, addCoef.col = "black")
```

## Visualizing key social factors

```{r}
top_3_components <- as.data.frame(pca$x[, 1:3])

pca_with_geoid <- cbind(census$GEOID, top_3_components)
colnames(pca_with_geoid)[1] <- "GEOID"
census_pca <- census %>%
  left_join(pca_with_geoid, by = "GEOID") 
```

```{r}
ggplot() + 
    geom_sf(data=census_pca, aes(fill=PC3))
```

```{r}
leaflet(census_pca %>% st_transform(4326)) %>%
  addProviderTiles(provider=providers$CartoDB.Positron) %>%
  addPolygons(fillColor = ~ pal(PC3),
              weight=2,
              opacity=0.5,
              color="white",
              fillOpacity = 0.5)
```

## Closing thoughts